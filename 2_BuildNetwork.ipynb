{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import urllib.request\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we cleaned up the data we can build the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1245214/1245214 [00:35<00:00, 35138.56it/s]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_pickle('LargeData/edges.pkl')\n",
    "author_posts = dict()\n",
    "for post in tqdm(range(data.shape[0])):\n",
    "    # Create a dictionary of authors and their flair, who they answered and their comment\n",
    "    author_name = data['author'][post]\n",
    "    author_flair = data['flair'][post]\n",
    "    answered = data['addressee'][post]\n",
    "    comment = data['comment'][post]\n",
    "    comment_id = data['id'][post]\n",
    "    \n",
    "    # Add author to dictionary or add attributes\n",
    "    if author_name not in author_posts:\n",
    "        author_posts[author_name] = [author_flair,[answered],[comment],[comment_id]]\n",
    "    else:\n",
    "        author_posts[author_name][1].append(answered)\n",
    "        author_posts[author_name][2].append(comment)\n",
    "        author_posts[author_name][3].append(comment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/'\n",
    "data_path = 'data/'\n",
    "file = 'links2022.ndjson'\n",
    "\n",
    "data = pd.read_json(data_path + file, lines=True)\n",
    "data = data.rename(columns={'out_going':'author','in_going':'addressee'})\n",
    "author_posts = dict()\n",
    "for post in tqdm(range(data.shape[0])):\n",
    "    # Create a dictionary of authors and their flair, who they answered and their comment\n",
    "    author_name = data['author'][post]\n",
    "    author_flair = data['flair'][post]\n",
    "    answered = data['addressee'][post]\n",
    "    comment = data['comment'][post]\n",
    "    comment_id = data['id'][post]\n",
    "    \n",
    "    # Add author to dictionary or add attributes\n",
    "    if author_name not in author_posts:\n",
    "        author_posts[author_name] = [author_flair,[answered],comment,[comment_id]]\n",
    "    else:\n",
    "        author_posts[author_name][1].append(answered)\n",
    "        author_posts[author_name][2] += comment\n",
    "        author_posts[author_name][3].append(comment_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directed graph\n",
    "DirectedGraph = nx.MultiDiGraph()\n",
    "for author_name in author_posts.keys():\n",
    "    # Add nodes to the graph\n",
    "    DirectedGraph.add_node(author_name,flair=author_posts[author_name][0],comments=author_posts[author_name][2])\n",
    "\n",
    "for author_name in author_posts.keys():\n",
    "    # Add edges\n",
    "    for edge_to in author_posts[author_name][1]:\n",
    "        if edge_to != None:\n",
    "            DirectedGraph.add_edge(author_name,edge_to,comments=author_posts[author_name][2],comment_id=author_posts[author_name][3])\n",
    "\n",
    "# Create folder if it does not exist\n",
    "if not os.path.exists('LargeData'):\n",
    "    os.makedirs('LargeData')\n",
    "    \n",
    "# Save authors as a pickle file\n",
    "pickle.dump(DirectedGraph, open('LargeData/Graph.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Andre\\OneDrive - Danmarks Tekniske Universitet\\Social Data Science\\Projekt_git\\MBTI\\2_BuildNetwork.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Andre/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Social%20Data%20Science/Projekt_git/MBTI/2_BuildNetwork.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Save authors as a pickle file\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Andre/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Social%20Data%20Science/Projekt_git/MBTI/2_BuildNetwork.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pickle\u001b[39m.\u001b[39mdump(data, \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mLargeData/Graph.pkl\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pickle.dump(data, open('LargeData/data2022.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.17 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4283141bebd715001f35122986f72053f481d7843d97eb240b72cdbb548092ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
